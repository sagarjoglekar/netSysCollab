\section{Abstract}
Sentiment analysis in Online social networks (OSNs) is a very active field of research. The prime research motive of sentiment analysis in OSNs has been analysing textual data shared over popular networks like Twitter and Facebook. But with the explosive growth of smartphone industry, inclusion of other media factors are on the rise. Mediums like videos, photos and audio convey much more information about the context of a social interaction than plain text. This has posed an interesting prospect for computer science i.e. inclusion of human affects conveyed through these mediums to allow another dimension for social interactions. These mediums however pose a higher complexity in problem space. Our paper tries to explore this space by including neural network based approaches and also shows that using heterogeneous network designs together can give us a much higher precision in understanding the sentimental context of a media. In this paper we look at commercially available techniques, and compare results with custom designed neural networks. Finally we explore possibility of combining different approaches and benchmark them against some popular datasets in the wild 