\section{Abstract}
Sentiment analysis in Online social networks (OSNs) is a very active field of research. The prime research motive of sentiment analysis in OSNs has been analysing textual data shared over popular networks like Twitter and Facebook. But with the explosive growth of smartphone industry, inclusion of other media factors are on the rise. Mediums like videos, photos and audio convey much more information about the context of a social interaction than plain text. This has posed an interesting prospect for computer science i.e. inclusion of human affects conveyed through these mediums to allow another dimension for social interactions. These mediums however pose a higher complexity in problem space. Our paper tries to approach this space in three stages. First we try to establish a subspace of the greater media retrieval problem that applies to the context of social media. Then we try to do a comparative study of emotion recognition systems  by including neural network based approaches. Finally our paper also shows that using heterogeneous emotion recognition designs together can give us a much higher precision in understanding the sentimental context of a socially shared media. We ultimately establish several performance benchmarks by testing the systems against several popular datasets in the wild. 