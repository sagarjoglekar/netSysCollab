\begin{abstract}
Recent advances in deep neural networks and generative adversarial networks allow us to both create discriminative models and invert the processes to enable generative models, capable of generating image samples very close to real world natural images.
This has proven a useful tool in visualizing what a network learns when it learns to classify cats, dogs and objects. The challenge is to understand whether the same approaches can be useful in understanding much more abstract and meta properties like Beauty, 
Liveliness, depression etc. This paper proposes a pipeline and the necessary framework to infer affective components in urban images.
\end{abstract}